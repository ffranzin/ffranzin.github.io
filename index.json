[{"categories":null,"contents":"","permalink":"https://ffranzin.github.io/publications/a-raster-based-approach-for-waterbodies-mesh-generation/","tags":["Mesh Generation","Geographic Information System (GIS)","Large Scale scenarios","tool programming","optimization"],"title":"A Raster-based Approach for Waterbodies Mesh Generation"},{"categories":null,"contents":"","permalink":"https://ffranzin.github.io/publications/accurate-real-time-physics-simulation-for-large-worlds/","tags":["Real-time Physics Simulation","Large scale scenarios","Floating-point Precision"],"title":"Accurate Real-time Physics Simulation for Large Worlds"},{"categories":null,"contents":"","permalink":"https://ffranzin.github.io/publications/gpu-based-rendering-and-collision-simulation-of-ground-vegetation-in-large-scace-virtual-scenarios/","tags":["Ground Vegetation","Collision Simulation","GPU-based","GPU-instancing","real-time","large scale scenarios","optimization","Rendering"],"title":"GPU-Based Rendering and Collision Simulation of Ground Vegetation in Large-Scace Virtual Scenarios"},{"categories":null,"contents":"","permalink":"https://ffranzin.github.io/publications/procedural-editing-of-virtual-terrains-using-3d-bezier-curves/","tags":["Bezier Curves","procedural","terrain editing","tool programming","terrain carving","virtual terrains","optimization"],"title":"Procedural Editing of Virtual Terrains Using 3D Bezier Curves"},{"categories":null,"contents":"","permalink":"https://ffranzin.github.io/publications/gpu-based-real-time-procedural-distribution-of-vegetation-on-large-scale-virtual-terrains/","tags":["Procedural Generation","Large scale scenarios","Virtual terrains","Real-time","GPU-based","optimization","Rendering"],"title":"GPU-Based Real-Time Procedural Distribution of Vegetation On Large-Scale Virtual Terrains"},{"categories":null,"contents":"","permalink":"https://ffranzin.github.io/publications/uma-framework-para-distribuicao-gerenciamento-e-renderizacao-de-vegetacao-em-cenarios-virtuais-massivos-em-tempo-real/","tags":["Vegetation","procedural generations","Virtual Landscapes","Collision Simulation","GPU-Based","Large Scale scenarios","Real-Time","optimization","Rendering"],"title":"Uma Framework para distribuicao, gerenciamento e renderizacao de vegetacao em cenarios virtuais massivos em tempo real"},{"categories":null,"contents":" .container { display: table; width: 100%; float: left; } .container div { display: table-cell; } * { box-sizing: border-box; } /* Create three equal columns that floats next to each other */ .column { float: left; width: 33%; padding: 10px; height: 300px; /* Should be removed. Only for demonstration */ } /* Clear floats after the columns */ .row:after { content: \"\"; display: table; clear: both; }  I entered the game industry as a 3D modeler, knowledge which I got as a hobby/curiosity. A few years later, I found myself facing several challenges and breaking computational barriers. With six years of experience working as a programmer and technical artist, I acquired in-depth experience in 3D modeling, game and graphics development. In addition, I am also familiar with other processes of the artistic pipeline.\nI like to be involved in challenging tasks, especially those that need performance and/or storage scalability. I\u0026rsquo;m also fascinated with programming challenges mixed with artistic. In this aspect, I am passionate about procedural generation and automated solutions to decorate scenarios. I am an analytical thinker and an effective team worker with an open mind for feedback and new ideas.\n  MAIN INTERESTS  Game Development Computer Graphics Real-time Rendering Procedural Generation Tech-art   EDUCATION  \u0026#xf19d; MSc in Computer Graphics, 2020  Universidade Federal de Santa Maria    \u0026#xf19d; BSc in Computer Science, 2018  Universidade Federal de Santa Maria  INFO   ffranzin@inf.ufsm.br   (+55) 55 99168-5461    linkedin.com/in/ffranzin    github.com/ffranzin    Santa Maria, RS, Brazil    ","permalink":"https://ffranzin.github.io/_index-copy/","tags":null,"title":"Home"},{"categories":null,"contents":"","permalink":"https://ffranzin.github.io/publications/aplica%C3%A7%C3%A3o-de-t%C3%A9cnicas-procedurais-em-gpu-para-renderiza%C3%A7%C3%A3o-de-nuvens-volum%C3%A9tricas-em-tempo-real/","tags":["Procedural Clouds","Procedural generation","Ray Marching","Noise","Rendering"],"title":"Aplicacao de tecnicas procedurais em GPU para renderizacao de nuvens volumetricas em tempo real"},{"categories":null,"contents":"","permalink":"https://ffranzin.github.io/publications/using-active-mediators-and-passive-extractors-inside-materialized-data-integration-systems/","tags":["Data extraction","data integration","data analysis automation"],"title":"Using Active Mediators and Passive Extractors Inside Materialized Data Integration Systems"},{"categories":null,"contents":"Intro Doesn\u0026rsquo;t matter whether it\u0026rsquo;s a CakePHP app for a client, your own personal CMS, or any other web based application. If your passing around passwords or other sensitive info you should really implement SSL. SSL provides 2 main perks to your visitors.\n First it encrypts all communication that flies across the web. This prevents curious or devious billies from getting your secrets. Secondly it ensures to the user that your server is in fact who it claims, and not a nasty \u0026lsquo;man in the middle\u0026quot; attack. Finally it gives your site that touch of class\u0026hellip;. which of course a classy person like yourself relies on.  Once you implement SSL certificates on your server you\u0026rsquo;ll want to require secure connections using Apache\u0026rsquo;s rewrite module. Now I won\u0026rsquo;t dwell on the creation and signing of certificates, its already well documented. If your just starting out though,heres a few links I recommend;\n Creating self-signed certificates (free, but should only be used internally or for testing, users will; see an \u0026lsquo;Untrusted\u0026quot; warning) Requesting a CA Signed certificate (not free, but the final certificate is trusted and seamless for users)  The second link uses the schools internal CA, you will need to pay a public CA like Entrust or Verisign. All of this information is aimed at \u0026lsquo;nix or solaris servers running apache. Why? cause a production windows server is laughable :-p\nNow that you have a certificate, whats next? So there you are you have a shiny new Certificate and Server key, how do you force visitors to your apache driven site to use the SSL? You copied the certificates into the appropite locations right? And you have made the needed changes in httpd.conf right? So now when you view https://example.com you see a \u0026lsquo;trusted\u0026rsquo; warning or your site right? If No to any of these than this article does a pretty good job of outlining those steps.\nThe SSL Works, How do I force connections to use it? First you need to decide if you want to force every page on your site to use SSL, or only a particular sub-domain, or maybe just your admin directory. Since the overhead is minimal there is no harm is forcing the entire domain to leverage SSL, but if it is a self-signed certificate for your personal use than you\u0026rsquo;ll most certainly want to restrict its use to your own areas. This prevents users from seeing that nasty warning \u0026ldquo;This server is not trusted\u0026rdquo; You\u0026rsquo;ll know if your using SSL because the url prefix changes from http to https (s for secure).\nForcing entire domain to use SSL You want any visit, any where to use ssl. This probably the simplest solution. Create or append to your htaccess file in the top directory of your server. Some people use a port check (80 is typically http, while 443 is https) but if you have alernate configs or the user just adds :8080 to the end of the url this method is useless. Instead check whether the https environmental variable is set, if not then redirect.\nRewriteCond %{HTTPS} !=on RewriteRule ^(.*)$ https://%{SERVER_NAME}$1 \\[R,L\\] Forcing sub-domains to use SSL Maybe you only want mysecretarea.example.com to use SSL, that\u0026rsquo;s easy enough. Its the same premise as above, but you move the htaccess file into the directory that corresponds to the subdomain. Also change the second line like below;\nRewriteCond %{HTTPS} !=on RewriteRule ^(.*)$ https://mysecretarea.%{SERVER_NAME}$1 \\[R,L\\] Forcing a directory to use SSL This method cn get a little hairier if your using aliases or redirects on top of this one. You\u0026rsquo;ll need to consider what order the commands are read. The basic principle is like so. You want all visits to example.com/admin to use ssl. Create a htaccess file in the parent directory. Again will check for the https variable, but this time we also check for the sub-directory to be in the path.\nRewriteCond %{HTTPS} !=on RewriteRule ^/admin/(.*)$ https://%{SERVER_NAME}/admin/$1 \\[R,L\\] ","permalink":"https://ffranzin.github.io/blog/force-ssl/","tags":["apache","apache","redirect","rewrite","ssl","web development"],"title":"Forcing Visits to use SSL"},{"categories":null,"contents":" .center { display: block; margin-left: auto; margin-right: auto; max-width: 95%; } .row { display: flex; margin-left: auto; margin-right: auto; max-width: 95%; } .column { flex: 25%; padding: 2px; } video { width: 70%; height: auto; display: block; margin-left: auto; margin-right: auto; } #player-overlay { position: absolute; display: none; top: 0; left: 0; width: 100%; height: 100%; background-color: #000 z-index:999; }  I prototyped two solutions to break glass.\n\nDescription Technique 1 - Projecting broken glass patterns in screen space\nThis approach is specifically designed to simulate the effect of broken glass caused by projectiles such as gunshots. Raycasts are used to detect the impact points with glass surfaces and then project realistic patterns of broken glass around those points. The process is entirely done in screen-space, ensuring a correct projection of the patterns even for non-static glass surfaces.\n\nDescription Technique 2 - Procedural broken glass\nThis approach is designed to break larger areas of glass using objects (e.g., stones). To achieve this, a combination of a mask and a pattern are used to simulate the effect of broken glass. When an object is thrown, many processes are done to update the mask relative to the destroyed region. We also deal with what we call Floating Zones: glass without contact with another surface. For example, in the image below, it is possible to note that the central region of glass will also be destroyed by destroying the only area in contact with the wall.\n\nResults\nBelow we have a short video demonstrating the results obtained. It is important to highlight that it is essential to use a particle system for more immersive results. In addition, this project was developed just for fun and needs to be improved to be inserted in a commercial game.\n ","permalink":"https://ffranzin.github.io/projects/creations/breaking-glass/","tags":["Compute Shaders","Computer Graphics","Procedural","Shader","Real-time","Collision Simulation"],"title":"Break Glass"},{"categories":null,"contents":" * { box-sizing: border-box; } .img-container-x4 { float: left; width: 25%; padding: 1px; } .img-container-x4:hover img { float: left; width: 150%; padding: 1px; } .clearfix::after { content: \"\"; clear: both; display: table; }  I proposed and migrated a feature that compares millions of human faces to use GPU power.\n\nDescription\nI recently made a breakthrough in the field of face recognition technology by converting a feature that was previously limited to CPU processing to GPU processing using Cuda. This conversion has drastically reduced the processing time required for comparing N faces with another N faces.\nTo better understand the magnitude of this achievement, imagine comparing 5 million faces with another 5 million faces (that is a small dataset if compared to ours clients). This would require an astonishing 25 trillion comparisons! Before the GPU conversion, this task would have taken several days to process on a CPU. However, with the new GPU processing, it can be completed in just a few minutes/hours.\n","permalink":"https://ffranzin.github.io/projects/creations/facematch/","tags":["Cuda","Optimization"],"title":"Facial Recognition Optimization"},{"categories":null,"contents":" * { box-sizing: border-box; } .img-container { float: left; width: 49%; padding: 2px; } .clearfix::after { content: \"\"; clear: both; display: table; } .center { display: block; margin-left: auto; margin-right: auto; max-width: 70%; } #vertical-line { float: left; height: 500px; width: 1px; background-color: black; } .vertical-line { border-right:1px solid #000; }  I encouraged managers and guided artists in optimizing 3D assets and game scenarios to create real-time cutscenes, resulting in more manageable and less time-consuming changes.\n\nDescription\nDue to over-detailed 3D assets, we had a higgh rendering cost and was obligated to render cutscenes for game animations offline. Consequently, minor changes took days to re-render these cutscenes. In addition, it is common to receive change requests of the client, increasing headaches and rework. To address these issues, I conducted optimizations tests for proof-of-concept and introduced the new approach for managers and colleagues, rendering the entire scenario in real-time. To accomplish this, I optimized the 3D models and followed best practices for modeling/performance, considering my undestanding about the low-level of rendering.\nAfter my tests, I guided artists to optimize all 3D assets and game scenarios. Initially, we combined the meshes of objects to reduce the number of objects and materials, focusing on reducing draw-calls. In a second phase, we worked on the geometries of objects, which had an excessive number of vertices and a disparity between object size and level of detail. In this case, many small and occluded objects had an extreme level of detail that added high rendering costs.\nBelow, a demonstration a comparison of the 3D model before (left) and after (right) implementing the improvements.\n   \n There were also significant gains in the vehicle\u0026rsquo;s internal parts, but it cannot be shown for privacy reasons.\n \nResults\nAfter the improvements, the cutscenes were converted to animations running in real-time using the Unity engine. Changes are now far more manageable and less time-consuming. It is also possible to keep software up to date with new technologies, such as more realistic rendering methods or resolutions (e.g., full HD, 4K). This is possible just by doing a simple game\u0026rsquo;s rebuild instead of hours -or even days- of rendering cutscenes.\n","permalink":"https://ffranzin.github.io/projects/creations/game-assets-optimizations/","tags":["Optimization","Performance","Tutoring","Real-time"],"title":"Game Assets Optimizations"},{"categories":null,"contents":" * { box-sizing: border-box; } .video-container { float: left; width: 50%; padding: 2px; } .clearfix::after { content: \"\"; clear: both; display: table; } .center { display: block; margin-left: auto; margin-right: auto; max-width: 50%; } video { width: 99%; height: auto; display: block; margin-left: auto; margin-right: auto; }  New requirements significantly increased the number of simulated game entities, putting the game at a critical stage in terms of performance. In this context, I took responsibility for investigating and fixing performance bottlenecks.\n\nDescription\nI\u0026rsquo;ve scanned game components such as audio sources, animators, particle systems, and entities' controllers to identify bottlenecks and apply improvements. In addition, our physics simulation uses an intermediate Layer between PhysX and Unity to deal with the loss of numerical precision in large-scale scenarios (more details). With new entities being physically simulated, the solution presented what was already expected: scalability problems. In this context, I assumed the responsibility for identifying improvements for it. After studying how physical simulations work, I adapted our approach to fixing the architectural conflicts between PhysX\u0026rsquo;s data structures and the continuous cache miss caused by our Layer.\n\nResults\nAfter four months of massive refactoring, performance returned to a level capable of supporting the client\u0026rsquo;s new requirements. In addition, many of the decisions have increased the game\u0026rsquo;s scalability for future needs.\nThe video below shows some performance comparisons of before and after improvements. It shows some test cases moving 4 ASTROS batteries (composed of ~14 military vehicles each). The camera focuses on a particular battery, but another three are moving. It is possible to notice that the application was unusable for real-time purposes before improvements. On the other hand, it is possible to see a significant evolution in the performance aspect after the improvements.\n ","permalink":"https://ffranzin.github.io/projects/creations/game-optimizations/","tags":["Optimization","Performance","Memory Management","Data Structure"],"title":"Game Optimizations"},{"categories":null,"contents":" * { box-sizing: border-box; } .img-container { float: left; width: 25%; padding: 2px; } .video-container { float: left; width: 50%; padding: 2px; } .clearfix::after { content: \"\"; clear: both; display: table; } .center { display: block; margin-left: auto; margin-right: auto; max-width: 50%; }  I developed a solution for the real-time long-lasting grasses deformation and terrain trails according to the vehicles' and characters' movements.\n\nMotivation\nIn the context of military simulations, the deformation of terrains and grasses according to the movement of military vehicles is dangerous, as it can reveal the position to the enemies. Thus, a feature to simulate this is widely imperative. This functionality was desired but always denied by the development team due to several computational challenges. The main one was the incalculable storage cost to deform grams and keep them bent for many hours or even days of simulation in large-scale scenarios. Based on that, I prototyped an alternative solution that deals with low storage demand. It was presented to the customer, who aroused much interest. Thus, we improved and integrated the solution into the application.\n\nSolution\nThe approach involves dividing the scenarios into smaller sections using a quadtree and implementing a vector field to determine the direction of plants for each node. The vector fields are updated accordingly to objects move through the scenario. For performance purposes, complex 3D objects are approximated by planes and spheres (image below). When the colliders interact with the grass, vector fields are updated and the cost is assigned to restore each vector, allowing the simulation of different behaviors. For example, if a human disrupts the grass, it can quickly regain its shape, whereas if a vehicle damages the vector field, it may take longer to restore it (you can see both of these behaviors in the accompanying video).\n\nIn the vertex shader, grasses and small shrubs sample the vector fields to identify their orientation based on the interpolation of the closest vectors. Below we have a color debug showing the direction of the vectors in the vector fields after moving a vehicle. Also, we have the result after rendering, showing the vehicle\u0026rsquo;s path.\n     \nIn the fragment shader stage to texture the terrain the vector fields are sampled for a slight color attenuation. Here, the sample in the vector field is used to make a cross product with the up_vector, resulting in a scalar value used to attenuate the terrain fragment\u0026rsquo;s color. It is interesting to highlight deformation in far regions without 3D grams. The two images on the left show the before and after vehicles' movement, highlighting the path by terrain\u0026rsquo;s texturing. The two images on the right show the influence of the trails projected on terrain to improve the blend of deformed grams and the terrain.\n     \nCompute-shaders were used to deform and restore the vector fields. LOD and GPU-instancing techniques were used to optimize plants' rendering. Vector fields are kept in a TextureAtlas to reuse memory, preventing allocations and memory fragmentation. Vector fields far way from the camera without dynamic objects close are compressed (using the LZ4 algorithm) to save memory. When needed, the vector fields are decompressed. Then, it is possible to maintain deformations for long periods with a low storage cost. Due to the minimal variation in vector field data, compression rates can be extremely high, resulting in memory savings of 90-95%.\n\nResults\nBelow, on the left, is shown a demonstration with several colliders interacting with the plants simultaneously. On the right, is an example of a vehicle interacting with plants. Note that plants that interact with the base reestablish their original form more quickly than plants that interact with the tank\u0026rsquo;s tracks.\n    \nMore details can be seen here.\n","permalink":"https://ffranzin.github.io/projects/creations/grass-and-terrain-deformation/","tags":["Memory Management","Compute shaders","Computer graphics","Shader","Data compression","Real-time","GPU-Based","Collision Simulation","Large-Scale scenario"],"title":"Grass Deformation and Terrain Trails"},{"categories":null,"contents":" * { box-sizing: border-box; } .img-container-x4 { float: left; width: 25%; padding: 1px; } .img-container-x4:hover img { float: left; width: 150%; padding: 1px; } .clearfix::after { content: \"\"; clear: both; display: table; }  \nMossberg\n     \nFlamethrower\n      \nBBS-CM (High-poly)\n      \nGranade Launcher L79\n      \nBlaser R93\n    \nM107\n  ","permalink":"https://ffranzin.github.io/projects/creations/blender_modeling/","tags":["Blender","Modeling"],"title":"Modeling (Blender)"},{"categories":null,"contents":" * { box-sizing: border-box; } .img-container-x4 { float: left; width: 25%; padding: 1px; } .img-container-x4:hover img { float: left; width: 150%; padding: 1px; } .clearfix::after { content: \"\"; clear: both; display: table; } .center { display: block; margin-left: auto; margin-right: auto; max-width: 85%; }  I modeled a set of 3D bridges parts to compose a procedural bridge system.\n\nDescription\nI was involved in the system design and also modeled many bridge parts to compose a flexible Procedural Bridge System, capable of instantiating many bridges during loading time based on a set of initial and final points. My experience in programming and art proved to be valuable during the system design process, as it facilitated effective communication with my colleague responsible for coding. It also helped me to have a straightforward understanding of the steps he followed, which enabled me to model a set of accurate 3D bridges' parts that met his needs.\nBelow are four variations of bridges created based on existing examples within the Brazilian Army\u0026rsquo;s training fields in Goias/Brazil. We also have a comparison of changing the starting and ending points of one bridge, resulting in a longer bridge.\n     \u0026#8595;\n  ","permalink":"https://ffranzin.github.io/projects/creations/procedural-bridge-system/","tags":["Procedural","Modeling","UV unwrapping","Texturing"],"title":"Procedural Bridge System"},{"categories":null,"contents":" * { box-sizing: border-box; } .img-container-x4 { float: left; width: 25%; padding: 1px; } .img-container-x4:hover img { float: left; width: 150%; padding: 1px; } .clearfix::after { content: \"\"; clear: both; display: table; }  \nAged Wood\n    \nMuddy with Trails\n    \nBark with Knots and moss\n    \nGround with Roots\n   ","permalink":"https://ffranzin.github.io/projects/creations/substance_designer/","tags":["Substance Designer","Procedural Material"],"title":"Procedural Materials - Substance Designer"},{"categories":null,"contents":" * { box-sizing: border-box; } .img-container-x4 { float: left; width: 33%; padding: 1px; } .img-container-x4:hover img { float: left; width: 150%; padding: 1px; } .clearfix::after { content: \"\"; clear: both; display: table; } video { width: 70%; height: auto; display: block; margin-left: auto; margin-right: auto; }  To solve the limitations of an existing solution, I designed and developed a robust GPU-based vegetation system capable of handling thousands of trees and small plants efficiently in real-time.\n Motivation\nSmall environments are usually decorated by an artist or designer, which allows for fine control and pleasant-looking results. However, this process tends to be time-consuming and can quickly become impractical as the size of the environment increases. To deal with this, procedural solutions are commonly adopted as they speed up the process. Therefore, a solution was developed to distribute trees to the entire scenario and store the result for future use. However, the solution didn\u0026rsquo;t allow artists' editing and was completely CPU-based. The non-use of parallelism and the constant data transfers between CPU→GPU were the main factors that negatively impacted the performance. Distribution was CPU-based and offline, where minor changes required hours to redistribute and save the result. The solution was limited to distributing large and medium-sized trees to minimize application loading cost and memory consumption.\nIn this context, I designed and developed a new solution to manage vegetation in large-scale scenarios, solving the main limitations of an existing solution.\n Solution\nThe solution distributes vegetation procedurally on-demand in regions delimited by quadtree\u0026rsquo;s nodes. Nodes outside the camera\u0026rsquo;s frustum are destroyed as well as the plants of it. The plants remain in memory as long as the nodes are visible. If needed, the plants are deterministically redistributed as the nodes are recreated.\nFor distribution, the solution considers the influence of different aspects, such as terrain (e.g., slope and moisture), environmental (e.g., forest, lakes, and rivers zones), and human (e.g., villages and roads) aspects. These aspects must be normalizable values into [0, 1] for any scenario\u0026rsquo;s portion, encoded in 2D maps and/or vector data. Any other information discretized into [0-1] can be integrated.\nPlants are grouped using the concept of presets, characterized by a set of plants that share the same needs, considering distribution aspects and other fields used to exist in some scenario\u0026rsquo;s position. For example, a presets of plants that exist in 1) forest zones, 2) not in steep regions, and 3) in higher altitude regions. The system analyzes many presets in real-time and defines which preset best fits a particular scenario\u0026rsquo;s position. After determining the best presets for the analyzed position, any plant from that can be randomly selected to be placed.\nFor efficiency purposes, plants are analyzed frame-by-frame to establish a LOD to balance performance and visuals. The LOD is defined from the distance of each plant to the camera \u0026ndash;artists have control over it. Also, plants outside the frustum are discarded before rendering. Finally, the plant data is organized properly for use of GPU-instancing to speed up rendering.\nEven though vegetation processing takes place mainly on the GPU, other processes on the CPU can still interact with plants. Objects can deform grass and small bushes, keeping them bent for long periods with acceptable memory demands (see more details here). Plants' colliders are instanced on-demand based on physics objects' positions to allow collisions with large and medium-sized trees using the physics engine.\n  Results\nA scalable GPU-based solution was developed to deal with any type of plant (e.g., trees, bushes, and grass) in real-time. It is possible to save different configurations \u0026ndash;equivalent to biomes\u0026ndash; and use them in different scenarios. Artists can intuitively edit these configurations to get different layouts for plant placement, previewing the result immediately. In addition, artists can edit LOD parameters to get a trade-off between visuals and performance. The solution also extracts maximum parallelism and processing from modern GPUs.\nBelow we have four examples of created biomes.\n                     Below it is possible to see the rendering of several plants in a long-distance view.\n     Below we have a short performance demonstration.\n ","permalink":"https://ffranzin.github.io/projects/creations/procedural-vegetation-system/","tags":["Procedural","Compute shaders","Computer graphics","Shader","Real-time","GPU-Based","GPU-Instancing","Large-Scale scenario"],"title":"Procedural Vegetation System"},{"categories":null,"contents":" * { box-sizing: border-box; } .img-container-x4 { float: left; width: 25%; padding: 1px; } .img-container-x4:hover img { float: left; width: 150%; padding: 1px; } .clearfix::after { content: \"\"; clear: both; display: table; }  Octopus\n     \nPumpkin Head\n     \nSword\n   ","permalink":"https://ffranzin.github.io/projects/creations/zbrush_sculpting/","tags":["ZBrush","Sculpting"],"title":"Sculpting (ZBrush)"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml\n[outputs] home = [\u0026#34;HTML\u0026#34;, \u0026#34;JSON\u0026#34;] Searching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category\n... \u0026#34;contents\u0026#34;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026#34;tags\u0026#34;:{{ .Params.tags | jsonify }}{{end}}, \u0026#34;categories\u0026#34; : {{ .Params.categories | jsonify }}, ... Edit fuse.js options to Search static/js/search.js\nkeys: [ \u0026#34;title\u0026#34;, \u0026#34;contents\u0026#34;, \u0026#34;tags\u0026#34;, \u0026#34;categories\u0026#34; ] ","permalink":"https://ffranzin.github.io/search/","tags":null,"title":"Search Results"},{"categories":null,"contents":" video { width: 70%; height: auto; display: block; margin-left: auto; margin-right: auto; } #player-overlay { position: absolute; display: none; top: 0; left: 0; width: 100%; height: 100%; background-color: #000 z-index:999; }  I developed a dynamic structure to optimize access to mass datasets of polygons and polylines, representing areas like forests, lakes, roads, and rivers. This structure accelerated the terrain rendering ーwhich these data are projected by texturingー by +80% on average.\n\nDescription\nIn military simulations, the use of vector data to represent natural or human elements such as rivers, roads, highways, lakes, forests, and wetlands is standard practice. However, the sheer number of polylines or polygons required to accurately depict these elements can make access prohibitively expensive. To mitigate this issue, acceleration structures such as hash, BVH, and quadtree are commonly employed to reduce costs. These structures are only as efficient as their level of refinement, which is determined by the number of entities and area encapsulated by each unit (like a Quadtree\u0026rsquo;s node or Hash\u0026rsquo;s cells). Unfortunately, the memory consumption required to refine these structures becomes a limiting factor in larger scenarios, reducing potential performance gains. In addition, there is still a considerable cost to traverse these structures and their data.\nIn order to address the issue of costly access to acceleration structures by shaders, I have developed a middle layer structure. The video below demonstrates the difference in access (red fragments) to the acceleration structures before and after implementing this solution. With the Optimization toggle enabled (see in the bottom left), access to the acceleration structures is dramatically reduced (blue fragments indicating no access), as the middle layer structure identifies areas without any elements (river, road, \u0026hellip;), indicating that we can use standard materials (such as soil) in these areas. This results in a significant performance boost, often doubling performance in many cases.\n\n\n","permalink":"https://ffranzin.github.io/projects/creations/vector-feature-map/","tags":["Memory Management","Compute shaders","Computer graphics","Shaders","Data compression","Real-time","GPU-Based","Collision Simulation","Large-Scale Scenario"],"title":"Vector Data Access Optimization"},{"categories":null,"contents":" * { box-sizing: border-box; } .img-container-x4 { float: left; width: 25%; padding: 1px; } .img-container-x4:hover img { float: left; width: 150%; padding: 1px; } .clearfix::after { content: \"\"; clear: both; display: table; }  \nVehicles ASTROS II MK-6\n        Coded animation for vehicle leveling and a mechanical arm using inverse kinematics\n  \n Coded animation for vehicle\u0026rsquo;s mechanical arm using inverse kinematics\n  ","permalink":"https://ffranzin.github.io/projects/creations/full_artist_process/","tags":["Substance Painter","Blender","UV unwrapping","Texturing","Programming","Animation"],"title":"Vehicles creation - 3D artist"},{"categories":null,"contents":" * { box-sizing: border-box; } .img-container-x4 { float: left; width: 33%; padding: 1px; } .img-container-x4:hover img { float: left; width: 150%; padding: 1px; } .clearfix::after { content: \"\"; clear: both; display: table; } video { width: 70%; height: auto; display: block; margin-left: auto; margin-right: auto; }  I created a volumetric procedural clouds using ray-marching technique.\n\nDescription\nI have created a solution for real-time volumetric cloud rendering using the raymarching technique. This project was completed as part of my BSc work and was inspired by the solution proposed by the Guerrilla team.\nThe raymarching solution involves casting rays through a volume and incrementally advancing them until a stopping condition is reached. The stop condition typically is when the ray has lost all its energy. The volume is described by various noises (e.g., Perlin and Worley noise), which when combined effectively describe clouds. A series of parameters define how to interpret this volume, allowing for the creation of clouds with different sizes and sparseness, as well as with more or less \u0026ldquo;fluffy\u0026rdquo; details. Other parameters also allow for the description of how light rays behave, generating denser clouds with different visual characteristics.\nBelow are some samples with the results obtained.\n          \nMore details can be seen here.\n","permalink":"https://ffranzin.github.io/projects/creations/clouds/","tags":["Shader","Computer Graphics","Procedural","Real-time"],"title":"Volumetric Procedural Clouds"},{"categories":null,"contents":" .center { display: block; margin-left: auto; margin-right: auto; max-width: 95%; } .row { display: flex; margin-left: auto; margin-right: auto; max-width: 95%; } .column { flex: 25%; padding: 2px; }  I designed and guided an intern in developing a tool to generate polygonal meshes from mass polygons and polylines datasets, representing rivers (lines) and lakes (polygons) in large-scale scenarios.\n\nDescription\nThe purpose of this tool is to replace an outdated solution that struggled with scalability issues at entity junctions, such as river-river (line-line, on the left), rivers-rivers (lines-lines, in the middle), and river-lake (line-polygon, on the right). The previous solution employed a geometric approach that required treating each case of junctions, resulting in a system that was difficult to expand and maintain.\n\nTo get a simple and scalable solution for different types and amounts of entities' junctions, we developed a raster-based solution. The process starts by filling a texture (Buffering step, image below), where each pixel represents a small portion of the scenario and is set as a region Inside, Outside, or Border of a water body (river and/or lake). Next, the texture is traversed to extract the pixels defined as a Border (Vectorization step), which will be Simplified and Triangulated in the sequence. It results in a single mesh containing rivers and lakes from the region considered (whole scenario or small blocks for performance reasons). For performance purposes, compute-shader and acceleration structures were used.\n\nMore details can be seen here.\n","permalink":"https://ffranzin.github.io/projects/creations/water-bodies-meshes-generation/","tags":["Compute Shaders","Computer Graphics","Data Structure","GIS Data","GPU-Based","Large-Scale scenario","Tools","Tutoring"],"title":"Water planes mesh generation"}]